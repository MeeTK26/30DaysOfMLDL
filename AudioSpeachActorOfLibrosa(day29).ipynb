{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Qadysh5MPmW1cLVqqfQa6M8XC296-fkV",
      "authorship_tag": "ABX9TyOJYobSAjPRXTERDfDZ2srK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeeTK26/30DaysOfMLDL/blob/main/AudioSpeachActorOfLibrosa(day29).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "-UcQBtyP4Epz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAVDESS_DIR='/content/drive/MyDrive/Audio_Speech_Actors_01-24'\n",
        "emotions = {\n",
        "    '01': 'neutral',\n",
        "    '02': 'calm',\n",
        "    '03': 'happy',\n",
        "    '04': 'sad',\n",
        "    '05': 'angry',\n",
        "    '06': 'fearful',\n",
        "    '07': 'disgust',\n",
        "    '08': 'surprised'\n",
        "}"
      ],
      "metadata": {
        "id": "M4Tpw6T94HQt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "def extract_features(file_path, max_pad_len=174):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    pad_width = max_pad_len - mfccs.shape[1]\n",
        "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant') if pad_width > 0 else mfccs[:, :max_pad_len]\n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "5Gcjpn6Q4kbT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import resampy\n",
        "X, y = [], []\n",
        "for root, _, files in os.walk(RAVDESS_DIR):\n",
        "    for file in files:\n",
        "        if file.endswith(\".wav\"):\n",
        "            emotion = emotions[file.split(\"-\")[2]]\n",
        "            feature = extract_features(os.path.join(root, file))\n",
        "            X.append(feature)\n",
        "            y.append(emotion)"
      ],
      "metadata": {
        "id": "Qh9p9HM54yw_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YKAvQrtqG0US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(emotions))"
      ],
      "metadata": {
        "id": "FfZ_TaQo45Mo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "K9nWBogm5y3u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Reshape,Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, TimeDistributed\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(64, (3, 3), activation='relu', input_shape=(X.shape[1], X.shape[2], 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Reshape((-1, 64)),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    LSTM(64),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(emotions), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuXDsEcS52mG",
        "outputId": "72427bbf-e214-4a36-9505-8f9c5083c7d9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0VHeW_A-5-In",
        "outputId": "bd2a1166-7201-4ef3-d7d7-26814beb7593"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - accuracy: 0.1442 - loss: 2.1084 - val_accuracy: 0.1667 - val_loss: 2.0498\n",
            "Epoch 2/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - accuracy: 0.1509 - loss: 2.0617 - val_accuracy: 0.1944 - val_loss: 2.0398\n",
            "Epoch 3/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.1533 - loss: 2.0664 - val_accuracy: 0.1979 - val_loss: 2.0282\n",
            "Epoch 4/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.1662 - loss: 2.0527 - val_accuracy: 0.1667 - val_loss: 2.0264\n",
            "Epoch 5/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - accuracy: 0.1795 - loss: 2.0129 - val_accuracy: 0.1944 - val_loss: 1.9890\n",
            "Epoch 6/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.2029 - loss: 2.0053 - val_accuracy: 0.1875 - val_loss: 1.9736\n",
            "Epoch 7/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.2079 - loss: 1.9908 - val_accuracy: 0.2361 - val_loss: 1.9737\n",
            "Epoch 8/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.1912 - loss: 2.0016 - val_accuracy: 0.2431 - val_loss: 1.9670\n",
            "Epoch 9/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.2009 - loss: 1.9944 - val_accuracy: 0.2118 - val_loss: 1.9966\n",
            "Epoch 10/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - accuracy: 0.2170 - loss: 1.9648 - val_accuracy: 0.2778 - val_loss: 1.9434\n",
            "Epoch 11/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.2334 - loss: 1.9231 - val_accuracy: 0.2083 - val_loss: 1.9804\n",
            "Epoch 12/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.2528 - loss: 1.9332 - val_accuracy: 0.2361 - val_loss: 1.9821\n",
            "Epoch 13/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.2375 - loss: 1.9017 - val_accuracy: 0.2674 - val_loss: 1.9165\n",
            "Epoch 14/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.2806 - loss: 1.8856 - val_accuracy: 0.2882 - val_loss: 1.9118\n",
            "Epoch 15/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.2350 - loss: 1.8798 - val_accuracy: 0.2639 - val_loss: 1.9155\n",
            "Epoch 16/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 0.2881 - loss: 1.8735 - val_accuracy: 0.2604 - val_loss: 1.9114\n",
            "Epoch 17/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.2846 - loss: 1.8413 - val_accuracy: 0.2847 - val_loss: 1.8836\n",
            "Epoch 18/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.2762 - loss: 1.8289 - val_accuracy: 0.2743 - val_loss: 1.9288\n",
            "Epoch 19/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.2956 - loss: 1.8228 - val_accuracy: 0.2639 - val_loss: 1.8931\n",
            "Epoch 20/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.3267 - loss: 1.7884 - val_accuracy: 0.2847 - val_loss: 1.8715\n",
            "Epoch 21/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.3319 - loss: 1.7405 - val_accuracy: 0.2153 - val_loss: 1.9497\n",
            "Epoch 22/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.3221 - loss: 1.7609 - val_accuracy: 0.2882 - val_loss: 1.8632\n",
            "Epoch 23/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.3534 - loss: 1.7003 - val_accuracy: 0.2778 - val_loss: 1.8996\n",
            "Epoch 24/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.3491 - loss: 1.7004 - val_accuracy: 0.2847 - val_loss: 1.8824\n",
            "Epoch 25/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.3754 - loss: 1.6786 - val_accuracy: 0.2778 - val_loss: 1.8990\n",
            "Epoch 26/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.3628 - loss: 1.6333 - val_accuracy: 0.2257 - val_loss: 1.9537\n",
            "Epoch 27/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - accuracy: 0.4038 - loss: 1.5985 - val_accuracy: 0.2569 - val_loss: 1.9161\n",
            "Epoch 28/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.3805 - loss: 1.6156 - val_accuracy: 0.2708 - val_loss: 1.9143\n",
            "Epoch 29/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.3976 - loss: 1.5970 - val_accuracy: 0.2917 - val_loss: 1.9040\n",
            "Epoch 30/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 124ms/step - accuracy: 0.4119 - loss: 1.5391 - val_accuracy: 0.2674 - val_loss: 1.9739\n",
            "Epoch 31/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.4268 - loss: 1.5092 - val_accuracy: 0.2604 - val_loss: 1.9907\n",
            "Epoch 32/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.4801 - loss: 1.3999 - val_accuracy: 0.2500 - val_loss: 2.0283\n",
            "Epoch 33/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.4908 - loss: 1.3798 - val_accuracy: 0.2361 - val_loss: 2.0987\n",
            "Epoch 34/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.4588 - loss: 1.4377 - val_accuracy: 0.2431 - val_loss: 2.1130\n",
            "Epoch 35/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.5223 - loss: 1.3343 - val_accuracy: 0.2674 - val_loss: 2.1027\n",
            "Epoch 36/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.5235 - loss: 1.2812 - val_accuracy: 0.2257 - val_loss: 2.1660\n",
            "Epoch 37/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.5337 - loss: 1.2350 - val_accuracy: 0.2326 - val_loss: 2.2105\n",
            "Epoch 38/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.5669 - loss: 1.1499 - val_accuracy: 0.2535 - val_loss: 2.2595\n",
            "Epoch 39/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.5631 - loss: 1.1881 - val_accuracy: 0.2361 - val_loss: 2.3660\n",
            "Epoch 40/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.5672 - loss: 1.1751 - val_accuracy: 0.2257 - val_loss: 2.4728\n",
            "Epoch 41/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - accuracy: 0.5965 - loss: 1.1082 - val_accuracy: 0.2222 - val_loss: 2.3746\n",
            "Epoch 42/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6288 - loss: 1.0062 - val_accuracy: 0.2188 - val_loss: 2.4480\n",
            "Epoch 43/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.6487 - loss: 0.9850 - val_accuracy: 0.2083 - val_loss: 2.4953\n",
            "Epoch 44/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 0.6451 - loss: 0.8947 - val_accuracy: 0.2222 - val_loss: 2.6388\n",
            "Epoch 45/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.6786 - loss: 0.8978 - val_accuracy: 0.2500 - val_loss: 2.6477\n",
            "Epoch 46/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.7024 - loss: 0.8140 - val_accuracy: 0.2222 - val_loss: 2.7254\n",
            "Epoch 47/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.7137 - loss: 0.7619 - val_accuracy: 0.2396 - val_loss: 2.7630\n",
            "Epoch 48/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.6930 - loss: 0.8696 - val_accuracy: 0.2361 - val_loss: 2.8008\n",
            "Epoch 49/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.6729 - loss: 0.8673 - val_accuracy: 0.2222 - val_loss: 2.7117\n",
            "Epoch 50/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - accuracy: 0.7015 - loss: 0.7933 - val_accuracy: 0.2396 - val_loss: 2.8669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LPdx9Lq25-v_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7B4Oj8zKLrXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}